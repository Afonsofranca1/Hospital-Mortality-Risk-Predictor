{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Prediction – Imputation & Class‑Weighted Models (No SMOTE)\n",
    "\n",
    "This notebook builds Logistic Regression, Random Forest, XGBoost, and SVM classifiers.\n",
    "\n",
    "Key points:\n",
    "* **Missing values** imputed (median for numeric, mode for categorical)\n",
    "* **Class imbalance** handled via `class_weight='balanced'` (or `scale_pos_weight` for XGBoost)\n",
    "* **GridSearchCV** to optimise hyper‑parameters\n",
    "* Evaluation metric: **ROC AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\afons\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\afons\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\afons\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('data/HDHI Admission data.csv')\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# Binary outcome: 1 = death (EXPIRY)\n",
    "df['OUTCOME_BINARY'] = df['OUTCOME'].map({'DISCHARGE': 0, 'DAMA': 0, 'EXPIRY': 1})\n",
    "\n",
    "# Admission‑time features\n",
    "features = [\n",
    "    'AGE', 'GENDER', 'RURAL', 'TYPE OF ADMISSION-EMERGENCY/OPD',\n",
    "    'DM', 'HTN', 'CAD', 'CKD', 'SMOKING', 'ALCOHOL', 'PRIOR CMP',\n",
    "    'HB', 'TLC', 'GLUCOSE', 'UREA', 'CREATININE', 'BNP',\n",
    "    'ACS', 'STEMI', 'ATYPICAL CHEST PAIN', 'HEART FAILURE', 'VALVULAR',\n",
    "    'CHB', 'AKI', 'CVA INFRACT', 'AF', 'SHOCK', 'CHEST INFECTION'\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['OUTCOME_BINARY']\n",
    "\n",
    "# Standardise predictor names\n",
    "X.columns = X.columns.str.strip().str.replace(' ', '_')\n",
    "\n",
    "# Identify column types\n",
    "cat_cols = ['GENDER', 'RURAL', 'TYPE_OF_ADMISSION-EMERGENCY/OPD']\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Clean invalid strings\n",
    "X = X.replace(['EMPTY', 'NA', 'NaN', '--', '\\\\'], np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline with Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ColumnTransformer with imputation + scaling / one‑hot\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, num_cols),\n",
    "    ('cat', categorical_pipeline, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train–Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale_pos_weight for XGBoost: 13.26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After imputation, we can leave remaining NaNs to be handled by transformers\n",
    "# (SimpleImputer will be applied inside CV folds).\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "# Class ratio for XGBoost scale_pos_weight\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print('Scale_pos_weight for XGBoost:', round(pos_weight, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Definitions & Hyper‑parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    'logreg': (\n",
    "        LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'),\n",
    "        {'clf__C': [0.1, 1, 10]}\n",
    "    ),\n",
    "    'rf': (\n",
    "        RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        {'clf__n_estimators': [200, 400],\n",
    "         'clf__max_depth': [None, 10, 20]}\n",
    "    ),\n",
    "    'xgb': (\n",
    "        xgb.XGBClassifier(use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          scale_pos_weight=pos_weight,\n",
    "                          random_state=42),\n",
    "        {'clf__n_estimators': [200, 400],\n",
    "         'clf__max_depth': [3, 5],\n",
    "         'clf__learning_rate': [0.05, 0.1]}\n",
    "    ),\n",
    "    'svm': (\n",
    "        SVC(probability=True, class_weight='balanced'),\n",
    "        {'clf__C': [0.5, 1], 'clf__kernel': ['linear', 'rbf']}\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GridSearchCV & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afons\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:21:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "best_params",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d9016783-d6b3-4bbe-ad8b-b79719e6d864",
       "rows": [
        [
         "2",
         "xgb",
         "0.9529773014630623",
         "{'clf__learning_rate': 0.1, 'clf__max_depth': 3, 'clf__n_estimators': 200}"
        ],
        [
         "1",
         "rf",
         "0.9525427208912067",
         "{'clf__max_depth': 20, 'clf__n_estimators': 400}"
        ],
        [
         "3",
         "svm",
         "0.9176697527290578",
         "{'clf__C': 0.5, 'clf__kernel': 'rbf'}"
        ],
        [
         "0",
         "logreg",
         "0.9114767866047293",
         "{'clf__C': 0.1}"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.952977</td>\n",
       "      <td>{'clf__learning_rate': 0.1, 'clf__max_depth': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.952543</td>\n",
       "      <td>{'clf__max_depth': 20, 'clf__n_estimators': 400}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.917670</td>\n",
       "      <td>{'clf__C': 0.5, 'clf__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.911477</td>\n",
       "      <td>{'clf__C': 0.1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model       auc                                        best_params\n",
       "2     xgb  0.952977  {'clf__learning_rate': 0.1, 'clf__max_depth': ...\n",
       "1      rf  0.952543   {'clf__max_depth': 20, 'clf__n_estimators': 400}\n",
       "3     svm  0.917670              {'clf__C': 0.5, 'clf__kernel': 'rbf'}\n",
       "0  logreg  0.911477                                    {'clf__C': 0.1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for name, (clf, grid) in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    gs = GridSearchCV(pipe, grid, cv=skf, scoring='roc_auc',\n",
    "                      n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results.append({'model': name, 'auc': auc, 'best_params': gs.best_params_})\n",
    "\n",
    "    joblib.dump(best_model, f'best_model_{name}.pkl')\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='auc', ascending=False)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
